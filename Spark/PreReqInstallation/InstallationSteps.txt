Spark Installation

Install JDK and do path setup check 
	Using Download JDK
check java version in cmd : javac -version

downlaod Spark witgh hadoop 3
	https://www.apache.org/dyn/closer.lua/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz
Installation : extract the file in specific directory of Spark

Downlaod Winutils:
https://kontext.tech/article/825/hadoop-331-winutils
-> https://github.com/kontext-tech/winutils
download zip file and take which version you want and place in same directory
and place in smae folder the three istalled java, spark and winutils also



add three user paths in environment variable
Like Java-> JavaHome and java path till java folder
same SparkHome and Hadoop home

then edit environment variabvle you can add three variabkles
add in Path variable
Like %JavaHome%\bin
%SparkHome%\bin
%HadoopHome%\bin
 save it

Version Chek:
Java --Version

go to Spark placed directory using command line
then use this command  for check spark: C:\UserInstallation\Spark\bin>spark-shell --master local[3]
Spark-shell --master
	it will open scala command line

Create spark data frame
